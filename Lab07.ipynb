{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gamidirohan/MachineLearning-Lab/blob/main/Lab07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfWMUssDtXBF"
      },
      "source": [
        "# A2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRjonoZ5nh6q"
      },
      "source": [
        "Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iJu9Ng5TtbUv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQUblTGjnlh-"
      },
      "source": [
        "Class Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4GaX1znBnn9q"
      },
      "outputs": [],
      "source": [
        "class_labels = [\"acrostic\", \"ballad\", \"epigram\", \"haiku\", \"limerick\", \"sestina\", \"sonnet\", \"villanelle\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaBcpg7RovH7"
      },
      "source": [
        "Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8cJeVQjSo6Z1"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_train, X_test, y_train, y_test, class_labels):\n",
        "    train_accuracy = model.score(X_train, y_train)\n",
        "    test_accuracy = model.score(X_test, y_test)\n",
        "    print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "    # Generate classification report\n",
        "    y_pred = model.predict(X_test)\n",
        "    report = classification_report(y_test, model.predict(X_test), target_names=class_labels, zero_division=1)\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLEv3vk3o7WH"
      },
      "source": [
        "Save model as a .pkl file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9ItAkSIio9rv"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_file):\n",
        "    with open(model_file, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"Model saved as {model_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AjkOqRIpGQF"
      },
      "source": [
        "Load Embeddings from .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IKSmvLWyporp"
      },
      "outputs": [],
      "source": [
        "# Load the dataset into a DataFrame\n",
        "data_df = pd.read_csv(\"poems_data.csv\")\n",
        "\n",
        "# Drop rows with missing values\n",
        "data_df.dropna(inplace=True)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = data_df.drop(columns=['label']).values\n",
        "y = data_df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfHqeWkMptOP"
      },
      "source": [
        "Splitting data into Train and Test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "blkD-yaypvg-"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G8vwd8XpyMK"
      },
      "source": [
        "Parameter Grid for MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xfmNukoSpzy9"
      },
      "outputs": [],
      "source": [
        "mlp_param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (150,), (200,)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'learning_rate': ['constant', 'adaptive'],\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsg2eToCp299"
      },
      "source": [
        "RandomSearchCV for MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lrlv0sLVp5WS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "d64bf18c-2815-4aa0-cc93-43041c0a6999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-56ab47926900>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmlp_random_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             ParameterSampler(\n\u001b[1;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "mlp_random_search = RandomizedSearchCV(\n",
        "    estimator=MLPClassifier(),\n",
        "    param_distributions=mlp_param_grid,\n",
        "    n_iter=10,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "mlp_random_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A48Ugva9p8WV"
      },
      "source": [
        "Print MLP best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdqTs5jFp9_W"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters for MLP:\")\n",
        "print(mlp_random_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olq8F_gUp-sQ"
      },
      "source": [
        "Evaluate MLP with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EstOjZblqFLA"
      },
      "outputs": [],
      "source": [
        "mlp_model = mlp_random_search.best_estimator_\n",
        "print(\"Evaluating MLP...\")\n",
        "evaluate_model(mlp_model, X_train, X_test, y_train, y_test, class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LQjZe_PqG_f"
      },
      "source": [
        "Save MLP model as .pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMyi4vXsqIpZ"
      },
      "outputs": [],
      "source": [
        "mlp_model_file = \"mlp_model.pkl\"\n",
        "save_model(mlp_model, mlp_model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxRY0vC3qK7y"
      },
      "source": [
        "Defining parameter grid for Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FpwGN4FqNUf"
      },
      "outputs": [],
      "source": [
        "perceptron_param_grid = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
        "    'max_iter': [1000, 2000, 3000],\n",
        "    'tol': [1e-3, 1e-4, 1e-5]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsPPRR2VqQaT"
      },
      "source": [
        "Perform RandsearchCV for Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvns8g-GqTj9"
      },
      "outputs": [],
      "source": [
        "perceptron_random_search = RandomizedSearchCV(\n",
        "    estimator=Perceptron(),\n",
        "    param_distributions=perceptron_param_grid,\n",
        "    n_iter=10,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "perceptron_random_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKU0XJETqWil"
      },
      "source": [
        "Printing best Perceptron Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lCdtPvhqaVA"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters for Perceptron:\")\n",
        "print(perceptron_random_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StDeCRY7qdFS"
      },
      "source": [
        "Evaluate Perceptron with best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZPepuWAqfo4"
      },
      "outputs": [],
      "source": [
        "perceptron_model = perceptron_random_search.best_estimator_\n",
        "print(\"Evaluating Perceptron...\")\n",
        "evaluate_model(perceptron_model, X_train, X_test, y_train, y_test, class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWy5pdKFqh3N"
      },
      "source": [
        "Save model as .pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y_DfyE_qjne"
      },
      "outputs": [],
      "source": [
        "perceptron_model_file = \"perceptron_model.pkl\"\n",
        "save_model(perceptron_model, perceptron_model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOV8DJMvsdFV"
      },
      "source": [
        "## A3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akkfHI_ase0X"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ_GYNqIsg7W",
        "outputId": "25ef718b-4612-4db2-bd9a-453f2a74e9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.10/dist-packages (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install XlsxWriter\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OmfLmMmsh2e"
      },
      "source": [
        "Applying MinMax scaling on input data for Naive-Bayes (Since it doesn't take negative values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9KwxuvmatOlQ"
      },
      "outputs": [],
      "source": [
        "def scale_MinMax(X_train, X_test):\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "  return X_train_scaled, X_test_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ku4G43BtR6j"
      },
      "source": [
        "Initializing all classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "s6AHCr8vtTsL"
      },
      "outputs": [],
      "source": [
        "classifiers = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    \"CatBoost\": CatBoostClassifier(logging_level='Silent')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk4jPO_-tUi8"
      },
      "source": [
        "Train and evaluate all classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mojFI1HNtYbf",
        "outputId": "0a277e9d-14ca-4c86-ad33-7a8bd0b9f7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning hyperparameters for Naive Bayes...\n",
            "Train Accuracy: 0.75\n",
            "Test Accuracy: 0.68\n",
            "Classification Report for Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    acrostic       0.70      0.58      0.64        24\n",
            "      ballad       0.53      0.69      0.60        13\n",
            "     epigram       0.71      0.25      0.37        20\n",
            "       haiku       0.63      0.86      0.73        22\n",
            "    limerick       0.94      0.94      0.94        18\n",
            "     sestina       0.65      0.81      0.72        21\n",
            "      sonnet       0.57      0.87      0.68        15\n",
            "  villanelle       0.86      0.55      0.67        22\n",
            "\n",
            "    accuracy                           0.68       155\n",
            "   macro avg       0.70      0.69      0.67       155\n",
            "weighted avg       0.71      0.68      0.67       155\n",
            "\n",
            "Tuning hyperparameters for Support Vector Machine...\n",
            "Train Accuracy: 0.97\n",
            "Test Accuracy: 0.81\n",
            "Classification Report for Support Vector Machine:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    acrostic       0.90      0.79      0.84        24\n",
            "      ballad       0.61      0.85      0.71        13\n",
            "     epigram       0.78      0.70      0.74        20\n",
            "       haiku       0.74      0.91      0.82        22\n",
            "    limerick       1.00      0.94      0.97        18\n",
            "     sestina       0.79      0.90      0.84        21\n",
            "      sonnet       0.76      0.87      0.81        15\n",
            "  villanelle       1.00      0.59      0.74        22\n",
            "\n",
            "    accuracy                           0.81       155\n",
            "   macro avg       0.82      0.82      0.81       155\n",
            "weighted avg       0.84      0.81      0.81       155\n",
            "\n",
            "Tuning hyperparameters for Decision Tree...\n",
            "Train Accuracy: 1.00\n",
            "Test Accuracy: 0.46\n",
            "Classification Report for Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    acrostic       0.40      0.33      0.36        24\n",
            "      ballad       0.38      0.69      0.49        13\n",
            "     epigram       0.27      0.35      0.30        20\n",
            "       haiku       0.47      0.41      0.44        22\n",
            "    limerick       0.75      0.83      0.79        18\n",
            "     sestina       0.54      0.33      0.41        21\n",
            "      sonnet       0.73      0.53      0.62        15\n",
            "  villanelle       0.41      0.41      0.41        22\n",
            "\n",
            "    accuracy                           0.46       155\n",
            "   macro avg       0.49      0.49      0.48       155\n",
            "weighted avg       0.48      0.46      0.46       155\n",
            "\n",
            "Tuning hyperparameters for Random Forest...\n",
            "Train Accuracy: 1.00\n",
            "Test Accuracy: 0.80\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    acrostic       0.89      0.67      0.76        24\n",
            "      ballad       0.69      0.85      0.76        13\n",
            "     epigram       0.69      0.55      0.61        20\n",
            "       haiku       0.62      0.95      0.75        22\n",
            "    limerick       0.94      0.94      0.94        18\n",
            "     sestina       0.95      0.86      0.90        21\n",
            "      sonnet       0.81      0.87      0.84        15\n",
            "  villanelle       0.94      0.77      0.85        22\n",
            "\n",
            "    accuracy                           0.80       155\n",
            "   macro avg       0.82      0.81      0.80       155\n",
            "weighted avg       0.82      0.80      0.80       155\n",
            "\n",
            "Tuning hyperparameters for AdaBoost...\n",
            "Train Accuracy: 0.35\n",
            "Test Accuracy: 0.34\n",
            "Classification Report for AdaBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    acrostic       0.29      0.17      0.21        24\n",
            "      ballad       0.22      0.85      0.34        13\n",
            "     epigram       0.44      0.35      0.39        20\n",
            "       haiku       0.40      0.73      0.52        22\n",
            "    limerick       1.00      0.17      0.29        18\n",
            "     sestina       0.39      0.57      0.46        21\n",
            "      sonnet       1.00      0.00      0.00        15\n",
            "  villanelle       1.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.34       155\n",
            "   macro avg       0.59      0.35      0.28       155\n",
            "weighted avg       0.58      0.34      0.28       155\n",
            "\n",
            "Tuning hyperparameters for XGBoost...\n",
            "Train Accuracy: 1.00\n",
            "Test Accuracy: 0.79\n",
            "Classification Report for XGBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    acrostic       0.83      0.79      0.81        24\n",
            "      ballad       0.53      0.77      0.62        13\n",
            "     epigram       0.80      0.60      0.69        20\n",
            "       haiku       0.74      0.91      0.82        22\n",
            "    limerick       1.00      0.94      0.97        18\n",
            "     sestina       0.71      0.71      0.71        21\n",
            "      sonnet       0.81      0.87      0.84        15\n",
            "  villanelle       1.00      0.77      0.87        22\n",
            "\n",
            "    accuracy                           0.79       155\n",
            "   macro avg       0.80      0.80      0.79       155\n",
            "weighted avg       0.81      0.79      0.80       155\n",
            "\n",
            "Tuning hyperparameters for CatBoost...\n",
            "Train Accuracy: 1.00\n",
            "Test Accuracy: 0.84\n",
            "Classification Report for CatBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    acrostic       0.89      0.71      0.79        24\n",
            "      ballad       0.69      0.85      0.76        13\n",
            "     epigram       0.82      0.70      0.76        20\n",
            "       haiku       0.69      0.91      0.78        22\n",
            "    limerick       1.00      0.94      0.97        18\n",
            "     sestina       0.90      0.90      0.90        21\n",
            "      sonnet       0.81      0.87      0.84        15\n",
            "  villanelle       0.95      0.86      0.90        22\n",
            "\n",
            "    accuracy                           0.84       155\n",
            "   macro avg       0.85      0.84      0.84       155\n",
            "weighted avg       0.85      0.84      0.84       155\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "\n",
        "X_train_scaled, X_test_scaled = scale_MinMax(X_train, X_test)\n",
        "\n",
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"Tuning hyperparameters for {clf_name}...\")\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    train_accuracy = clf.score(X_train_scaled, y_train)\n",
        "    test_accuracy = clf.score(X_test_scaled, y_test)\n",
        "    print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "    # Generate classification report\n",
        "    print(f\"Classification Report for {clf_name}:\")\n",
        "    report = classification_report(y_test, clf.predict(X_test_scaled), target_names=class_labels, zero_division=1)\n",
        "    print(report)\n",
        "\n",
        "    # Store results\n",
        "    results[clf_name] = {\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "        \"Classification Report\": report\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXz2Xf_5ubh-"
      },
      "source": [
        "Create a DataFrame to tabulate the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a7K2XFCTI_gq"
      },
      "outputs": [],
      "source": [
        "# Create a Pandas Excel writer using XlsxWriter as the engine\n",
        "with pd.ExcelWriter('classifiers_performance.xlsx', engine='xlsxwriter') as writer:\n",
        "    for clf_name in classifiers.keys():\n",
        "        # Convert the classifier's performance metrics to a DataFrame\n",
        "        df = pd.DataFrame([results[clf_name]])\n",
        "\n",
        "        # Write the DataFrame to a specific sheet\n",
        "        df.to_excel(writer, sheet_name=clf_name, index=False)\n",
        "\n",
        "        # Optional: Auto-adjust columns' width\n",
        "        for column in df:\n",
        "            column_width = max(df[column].astype(str).map(len).max(), len(column))\n",
        "            col_idx = df.columns.get_loc(column)\n",
        "            writer.sheets[clf_name].set_column(col_idx, col_idx, column_width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwerqiL6uduL",
        "outputId": "366696b8-3a4a-4a28-a3b8-460a563fb02b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results Summary:\n",
            "                                                             Naive Bayes  \\\n",
            "Train Accuracy                                                  0.746774   \n",
            "Test Accuracy                                                   0.683871   \n",
            "Classification Report                precision    recall  f1-score   ...   \n",
            "\n",
            "                                                  Support Vector Machine  \\\n",
            "Train Accuracy                                                  0.967742   \n",
            "Test Accuracy                                                   0.812903   \n",
            "Classification Report                precision    recall  f1-score   ...   \n",
            "\n",
            "                                                           Decision Tree  \\\n",
            "Train Accuracy                                                       1.0   \n",
            "Test Accuracy                                                   0.464516   \n",
            "Classification Report                precision    recall  f1-score   ...   \n",
            "\n",
            "                                                           Random Forest  \\\n",
            "Train Accuracy                                                       1.0   \n",
            "Test Accuracy                                                        0.8   \n",
            "Classification Report                precision    recall  f1-score   ...   \n",
            "\n",
            "                                                                AdaBoost  \\\n",
            "Train Accuracy                                                      0.35   \n",
            "Test Accuracy                                                   0.341935   \n",
            "Classification Report                precision    recall  f1-score   ...   \n",
            "\n",
            "                                                                 XGBoost  \\\n",
            "Train Accuracy                                                       1.0   \n",
            "Test Accuracy                                                   0.793548   \n",
            "Classification Report                precision    recall  f1-score   ...   \n",
            "\n",
            "                                                                CatBoost  \n",
            "Train Accuracy                                                       1.0  \n",
            "Test Accuracy                                                    0.83871  \n",
            "Classification Report                precision    recall  f1-score   ...  \n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPdMvI8q/Tj6V3YfQjoh/je",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}